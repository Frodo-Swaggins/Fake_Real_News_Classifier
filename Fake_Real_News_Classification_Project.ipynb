{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPThbHRwPU/13fh1zy/1kth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frodo-Swaggins/Fake_Real_News_Classifier/blob/main/Fake_Real_News_Classification_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "PmuqCnss-sgo",
        "outputId": "5383d970-daab-4505-8560-bd24c41f06b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d1d5f2f639c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read in the datasets\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "copied_path_fake = '/content/drive/MyDrive/Fake.csv'\n",
        "copied_path_real = '/content/drive/MyDrive/True.csv'\n",
        "\n",
        "df_fake = pd.read_csv(copied_path_fake, encoding='latin-1')\n",
        "df_real = pd.read_csv(copied_path_real, encoding='latin-1')\n",
        "\n",
        "#drop all unnecassary info from the dataset\n",
        "df_fake = df_fake.iloc[:,[1]]\n",
        "df_real = df_real.iloc[:,[1]]\n",
        "\n",
        "#Add in a column for real an fake labels\n",
        "df_fake.insert(1,'Tag','fake')\n",
        "df_real.insert(1,'Tag','real')\n",
        "\n",
        "#Reduce the size of the dataset for training time purposes\n",
        "df_fake=df_fake.drop(df_fake.index[8000:],axis=0)\n",
        "df_real=df_real.drop(df_real.index[8000:],axis=0)\n",
        "\n",
        "# Stack the DataFrames on top of each other\n",
        "df = pd.concat([df_fake, df_real], axis=0)\n",
        "\n",
        "print(df)\n",
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-CS88t5-9kW",
        "outputId": "88575d9e-0be3-4b42-b7aa-08f437f341d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                                                   text   Tag\n",
            "0     Donald Trump just couldn t wish all Americans ...  fake\n",
            "1     House Intelligence Committee Chairman Devin Nu...  fake\n",
            "2     On Friday, it was revealed that former Milwauk...  fake\n",
            "3     On Christmas day, Donald Trump announced that ...  fake\n",
            "4     Pope Francis used his annual Christmas Day mes...  fake\n",
            "...                                                 ...   ...\n",
            "7995  NEW YORK/LOS ANGELES (Reuters) - The first pre...  real\n",
            "7996  WASHINGTON (Reuters) - Democratic presidential...  real\n",
            "7997  (Reuters) - Republican presidential candidate ...  real\n",
            "7998  WASHINGTON (Reuters) - The U.S. Senateâs sen...  real\n",
            "7999  WASHINGTON (Reuters) - The FBI is investigatin...  real\n",
            "\n",
            "[16000 rows x 2 columns]\n",
            "16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from textblob import Word\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import re                                  \n",
        "import string                             \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT8tPeSd_U_0",
        "outputId": "70304950-4051-4604-a3bf-5b55c7dc5e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Error loading english: Package 'english' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning(df, stop_words):\n",
        "\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
        "    print(df)\n",
        "\n",
        "    # Replacing the special characters\n",
        "\n",
        "    df['text'] = df['text'].str.replace('[^\\w\\s]', '')\n",
        "    print(df)\n",
        "\n",
        "    # Replacing the digits/numbers\n",
        "\n",
        "    df['text'] = df['text'].str.replace('\\d', '')\n",
        "    print(df)\n",
        "\n",
        "    # Removing stop words\n",
        "\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
        "    print(df)\n",
        "\n",
        "    # Lemmatization\n",
        "\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n",
        "    print(df)\n",
        "\n",
        "    return df\n",
        "\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "K34SzIIIAzAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = cleaning(df, stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-B6MrzZA9Rb",
        "outputId": "7df5232f-3a7b-4a6a-f0e9-4322e93467ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text   Tag\n",
            "0     donald trump wish american happy new year leav...  fake\n",
            "1     house intelligence committee chairman devin nu...  fake\n",
            "2     friday revealed former milwaukee sheriff david...  fake\n",
            "3     christmas day donald trump announced would bac...  fake\n",
            "4     pope francis used annual christmas day message...  fake\n",
            "...                                                 ...   ...\n",
            "7995  new yorklos angeles reuters first presidential...  real\n",
            "7996  washington reuters democratic presidential can...  real\n",
            "7997  reuters republican presidential candidate dona...  real\n",
            "7998  washington reuters u senateâs senior democrati...  real\n",
            "7999  washington reuters fbi investigating suspected...  real\n",
            "\n",
            "[16000 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text   Tag\n",
            "0     donald trump wish american happy new year leav...  fake\n",
            "1     house intelligence committee chairman devin nu...  fake\n",
            "2     friday revealed former milwaukee sheriff david...  fake\n",
            "3     christmas day donald trump announced would bac...  fake\n",
            "4     pope francis used annual christmas day message...  fake\n",
            "...                                                 ...   ...\n",
            "7995  new yorklos angeles reuters first presidential...  real\n",
            "7996  washington reuters democratic presidential can...  real\n",
            "7997  reuters republican presidential candidate dona...  real\n",
            "7998  washington reuters u senateâs senior democrati...  real\n",
            "7999  washington reuters fbi investigating suspected...  real\n",
            "\n",
            "[16000 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text   Tag\n",
            "0     donald trump wish american happy new year leav...  fake\n",
            "1     house intelligence committee chairman devin nu...  fake\n",
            "2     friday revealed former milwaukee sheriff david...  fake\n",
            "3     christmas day donald trump announced would bac...  fake\n",
            "4     pope francis used annual christmas day message...  fake\n",
            "...                                                 ...   ...\n",
            "7995  new yorklos angeles reuters first presidential...  real\n",
            "7996  washington reuters democratic presidential can...  real\n",
            "7997  reuters republican presidential candidate dona...  real\n",
            "7998  washington reuters u senateâs senior democrati...  real\n",
            "7999  washington reuters fbi investigating suspected...  real\n",
            "\n",
            "[16000 rows x 2 columns]\n",
            "                                                   text   Tag\n",
            "0     donald trump wish american happy new year leav...  fake\n",
            "1     house intelligence committee chairman devin nu...  fake\n",
            "2     friday revealed former milwaukee sheriff david...  fake\n",
            "3     christmas day donald trump announced would bac...  fake\n",
            "4     pope francis used annual christmas day message...  fake\n",
            "...                                                 ...   ...\n",
            "7995  new yorklos angeles reuters first presidential...  real\n",
            "7996  washington reuters democratic presidential can...  real\n",
            "7997  reuters republican presidential candidate dona...  real\n",
            "7998  washington reuters u senateâs senior democrati...  real\n",
            "7999  washington reuters fbi investigating suspected...  real\n",
            "\n",
            "[16000 rows x 2 columns]\n",
            "                                                   text   Tag\n",
            "0     donald trump wish american happy new year leav...  fake\n",
            "1     house intelligence committee chairman devin nu...  fake\n",
            "2     friday revealed former milwaukee sheriff david...  fake\n",
            "3     christmas day donald trump announced would bac...  fake\n",
            "4     pope francis used annual christmas day message...  fake\n",
            "...                                                 ...   ...\n",
            "7995  new yorklos angeles reuters first presidential...  real\n",
            "7996  washington reuters democratic presidential can...  real\n",
            "7997  reuters republican presidential candidate dona...  real\n",
            "7998  washington reuters u senateâs senior democrati...  real\n",
            "7999  washington reuters fbi investigating suspected...  real\n",
            "\n",
            "[16000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Add one hot encoding for the vocabularly from the dataset\n",
        "vocab_size = 10000\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in df['text']]\n",
        "max_length = 120\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "\n",
        "#Add encoding for the labels from the dataset\n",
        "lb=LabelEncoder()\n",
        "encoded_label = lb.fit_transform(df['Tag'])"
      ],
      "metadata": {
        "id": "hSfzpbY7BE72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "y=pd.get_dummies(encoded_label)\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_docs,y, test_size = 0.3, random_state = 42)"
      ],
      "metadata": {
        "id": "BZtcEp6cDW32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=16\n",
        "trunc_type= 'post'\n",
        "oov_tok=\"<OOV>\"\n",
        "\n",
        "Simple_RNN_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                             input_length=max_length),\n",
        "    tf.keras.layers.SimpleRNN(32),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "Simple_RNN_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYPUQhc_Dfu1",
        "outputId": "d1ecd2c6-126c-4fae-d702-73df4664478f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 120, 16)           160000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 32)                1568      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                330       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 161,920\n",
            "Trainable params: 161,920\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "Simple_RNN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "batch_size=2000\n",
        "history = Simple_RNN_model.fit(X_train, y_train, epochs = 30, batch_size=batch_size, verbose = 'auto')\n",
        "\n",
        "loss, accuracy, f1_score, precision, recall = Simple_RNN_model.evaluate(X_test, y_test, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGtWxUIXDvwB",
        "outputId": "0d1088e8-fbf3-4e45-8172-087156dda66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "6/6 [==============================] - 3s 226ms/step - loss: 0.6702 - acc: 0.5038 - f1_m: 0.4491 - precision_m: 0.5939 - recall_m: 0.3635\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 0.5943 - acc: 0.5507 - f1_m: 0.5757 - precision_m: 0.7304 - recall_m: 0.4769\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 1s 215ms/step - loss: 0.5224 - acc: 0.7479 - f1_m: 0.7016 - precision_m: 0.8940 - recall_m: 0.5782\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 0.4716 - acc: 0.9323 - f1_m: 0.7907 - precision_m: 0.9505 - recall_m: 0.6773\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 1s 214ms/step - loss: 0.4437 - acc: 0.9511 - f1_m: 0.6579 - precision_m: 0.9559 - recall_m: 0.5019\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 1s 211ms/step - loss: 0.4321 - acc: 0.9490 - f1_m: 0.6418 - precision_m: 0.9310 - recall_m: 0.4898\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 1s 206ms/step - loss: 0.4396 - acc: 0.9180 - f1_m: 0.5947 - precision_m: 0.9711 - recall_m: 0.4287\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 0.4178 - acc: 0.9246 - f1_m: 0.6048 - precision_m: 0.9730 - recall_m: 0.4389\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 1s 208ms/step - loss: 0.3903 - acc: 0.9624 - f1_m: 0.6380 - precision_m: 0.9783 - recall_m: 0.4734\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 1s 216ms/step - loss: 0.3778 - acc: 0.9673 - f1_m: 0.6490 - precision_m: 0.9540 - recall_m: 0.4919\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 1s 209ms/step - loss: 0.3656 - acc: 0.9726 - f1_m: 0.6522 - precision_m: 0.9642 - recall_m: 0.4929\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 0.3551 - acc: 0.9770 - f1_m: 0.6511 - precision_m: 0.9810 - recall_m: 0.4873\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 1s 216ms/step - loss: 0.3411 - acc: 0.9804 - f1_m: 0.6542 - precision_m: 0.9810 - recall_m: 0.4908\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 1s 240ms/step - loss: 0.3308 - acc: 0.9814 - f1_m: 0.6562 - precision_m: 0.9808 - recall_m: 0.4931\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 2s 349ms/step - loss: 0.3189 - acc: 0.9861 - f1_m: 0.6591 - precision_m: 0.9820 - recall_m: 0.4961\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 2s 300ms/step - loss: 0.3097 - acc: 0.9852 - f1_m: 0.6584 - precision_m: 0.9817 - recall_m: 0.4954\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 1s 212ms/step - loss: 0.2985 - acc: 0.9856 - f1_m: 0.6575 - precision_m: 0.9877 - recall_m: 0.4928\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 1s 217ms/step - loss: 0.2825 - acc: 0.9881 - f1_m: 0.6599 - precision_m: 0.9912 - recall_m: 0.4947\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 1s 215ms/step - loss: 0.2698 - acc: 0.9934 - f1_m: 0.6647 - precision_m: 0.9919 - recall_m: 0.4999\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 1s 214ms/step - loss: 0.2591 - acc: 0.9947 - f1_m: 0.6692 - precision_m: 0.9941 - recall_m: 0.5046\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 1s 210ms/step - loss: 0.2550 - acc: 0.9893 - f1_m: 0.6614 - precision_m: 0.9879 - recall_m: 0.4973\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 1s 216ms/step - loss: 0.2479 - acc: 0.9853 - f1_m: 0.7096 - precision_m: 0.9789 - recall_m: 0.5606\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 1s 214ms/step - loss: 0.2302 - acc: 0.9917 - f1_m: 0.9881 - precision_m: 0.9923 - recall_m: 0.9841\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 1s 214ms/step - loss: 0.2153 - acc: 0.9888 - f1_m: 0.9894 - precision_m: 0.9897 - recall_m: 0.9891\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 1s 207ms/step - loss: 0.1925 - acc: 0.9960 - f1_m: 0.9960 - precision_m: 0.9961 - recall_m: 0.9960\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 1s 209ms/step - loss: 0.1736 - acc: 0.9962 - f1_m: 0.9962 - precision_m: 0.9962 - recall_m: 0.9962\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 1s 208ms/step - loss: 0.1561 - acc: 0.9961 - f1_m: 0.9961 - precision_m: 0.9962 - recall_m: 0.9961\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 1s 213ms/step - loss: 0.1403 - acc: 0.9968 - f1_m: 0.9968 - precision_m: 0.9968 - recall_m: 0.9967\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 2s 306ms/step - loss: 0.1221 - acc: 0.9973 - f1_m: 0.9973 - precision_m: 0.9973 - recall_m: 0.9973\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 1s 221ms/step - loss: 0.1081 - acc: 0.9976 - f1_m: 0.9975 - precision_m: 0.9975 - recall_m: 0.9975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('loss : ',loss)\n",
        "print('accuracy : ',accuracy)\n",
        "print('f1 score : ',f1_score)\n",
        "print('precision : ',precision)\n",
        "print('recall : ',recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTikOqrXEhws",
        "outputId": "8f651fd9-9da3-4547-f128-e06ae33b9b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.12412045896053314\n",
            "accuracy :  0.9839583039283752\n",
            "f1 score :  0.9837433099746704\n",
            "precision :  0.9839516282081604\n",
            "recall :  0.9835416674613953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                             input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "GRU_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15ZxNjVZEnod",
        "outputId": "cc0850d9-1c87-4327-9932-4048bc7a7072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 120, 16)           160000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               9600      \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 170,272\n",
            "Trainable params: 170,272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "GRU_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "batch_size=2000\n",
        "history = GRU_model.fit(X_train, y_train, epochs = 30, batch_size=batch_size, verbose = 'auto')\n",
        "\n",
        "loss, accuracy, f1_score, precision, recall = GRU_model.evaluate(X_test, y_test, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1zzVfHWEwDv",
        "outputId": "efa6f93b-1b49-45a8-dc6f-7bd8b30ea3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "6/6 [==============================] - 11s 1s/step - loss: 0.6894 - acc: 0.5049 - f1_m: 0.4388 - precision_m: 0.5003 - recall_m: 0.4064\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.6814 - acc: 0.5126 - f1_m: 0.5355 - precision_m: 0.5238 - recall_m: 0.5483\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 8s 1s/step - loss: 0.6700 - acc: 0.6588 - f1_m: 0.7156 - precision_m: 0.6255 - recall_m: 0.8369\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.6521 - acc: 0.7656 - f1_m: 0.7601 - precision_m: 0.6483 - recall_m: 0.9185\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.6239 - acc: 0.7985 - f1_m: 0.7620 - precision_m: 0.6490 - recall_m: 0.9226\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.5807 - acc: 0.8587 - f1_m: 0.7666 - precision_m: 0.6511 - recall_m: 0.9317\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.5168 - acc: 0.8756 - f1_m: 0.7656 - precision_m: 0.6505 - recall_m: 0.9301\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.4275 - acc: 0.9001 - f1_m: 0.7647 - precision_m: 0.6499 - recall_m: 0.9288\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.3576 - acc: 0.9743 - f1_m: 0.7894 - precision_m: 0.6611 - recall_m: 0.9797\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.3219 - acc: 0.9777 - f1_m: 0.7901 - precision_m: 0.6592 - recall_m: 0.9857\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.2806 - acc: 0.9836 - f1_m: 0.7998 - precision_m: 0.6712 - recall_m: 0.9894\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.2360 - acc: 0.9891 - f1_m: 0.9236 - precision_m: 0.8660 - recall_m: 0.9951\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.2073 - acc: 0.9919 - f1_m: 0.9820 - precision_m: 0.9703 - recall_m: 0.9941\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.1775 - acc: 0.9941 - f1_m: 0.9919 - precision_m: 0.9885 - recall_m: 0.9954\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.1472 - acc: 0.9940 - f1_m: 0.9930 - precision_m: 0.9919 - recall_m: 0.9942\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.1216 - acc: 0.9944 - f1_m: 0.9942 - precision_m: 0.9936 - recall_m: 0.9949\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0954 - acc: 0.9963 - f1_m: 0.9961 - precision_m: 0.9955 - recall_m: 0.9966\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0744 - acc: 0.9971 - f1_m: 0.9969 - precision_m: 0.9963 - recall_m: 0.9974\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0576 - acc: 0.9976 - f1_m: 0.9977 - precision_m: 0.9972 - recall_m: 0.9983\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.0453 - acc: 0.9987 - f1_m: 0.9984 - precision_m: 0.9978 - recall_m: 0.9990\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.0352 - acc: 0.9991 - f1_m: 0.9988 - precision_m: 0.9982 - recall_m: 0.9995\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0250 - acc: 0.9994 - f1_m: 0.9992 - precision_m: 0.9987 - recall_m: 0.9997\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.0177 - acc: 0.9996 - f1_m: 0.9993 - precision_m: 0.9988 - recall_m: 0.9998\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0131 - acc: 0.9997 - f1_m: 0.9994 - precision_m: 0.9990 - recall_m: 0.9998\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.0102 - acc: 0.9996 - f1_m: 0.9996 - precision_m: 0.9994 - recall_m: 0.9998\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0083 - acc: 0.9997 - f1_m: 0.9997 - precision_m: 0.9997 - recall_m: 0.9998\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.0069 - acc: 0.9997 - f1_m: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0060 - acc: 0.9997 - f1_m: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.0052 - acc: 0.9997 - f1_m: 0.9997 - precision_m: 0.9997 - recall_m: 0.9998\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0047 - acc: 0.9997 - f1_m: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('loss : ',loss)\n",
        "print('accuracy : ',accuracy)\n",
        "print('f1 score : ',f1_score)\n",
        "print('precision : ',precision)\n",
        "print('recall : ',recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky8s3TErGPtT",
        "outputId": "ef0af45e-49f5-4426-bf01-0d033db88e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.023762129247188568\n",
            "accuracy :  0.9941666722297668\n",
            "f1 score :  0.9940705299377441\n",
            "precision :  0.9937752485275269\n",
            "recall :  0.9943749904632568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "LSTM_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq4N5wT5GVdd",
        "outputId": "00ed1335-485e-44f7-e19d-db13c6c19701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 120, 16)           160000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               12544     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173,216\n",
            "Trainable params: 173,216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "LSTM_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "batch_size=2000\n",
        "history = LSTM_model.fit(X_train, y_train, epochs = 30, batch_size=batch_size, verbose = 'auto')\n",
        "\n",
        "loss, accuracy, f1_score, precision, recall = LSTM_model.evaluate(X_test, y_test, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSlxxBqPGdg4",
        "outputId": "47cac797-ca8f-4141-f12c-23ca6e61684a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "6/6 [==============================] - 11s 1s/step - loss: 0.6914 - acc: 0.5009 - f1_m: 0.5024 - precision_m: 0.5159 - recall_m: 0.4903\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.6853 - acc: 0.5063 - f1_m: 0.5187 - precision_m: 0.5388 - recall_m: 0.5005\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.6745 - acc: 0.5487 - f1_m: 0.5677 - precision_m: 0.6570 - recall_m: 0.5001\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.6511 - acc: 0.5724 - f1_m: 0.5674 - precision_m: 0.6513 - recall_m: 0.5027\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.5919 - acc: 0.6383 - f1_m: 0.5698 - precision_m: 0.6600 - recall_m: 0.5014\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.4491 - acc: 0.8231 - f1_m: 0.6808 - precision_m: 0.8017 - recall_m: 0.5921\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.3883 - acc: 0.9616 - f1_m: 0.9383 - precision_m: 0.9632 - recall_m: 0.9153\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.3672 - acc: 0.9735 - f1_m: 0.7953 - precision_m: 0.9676 - recall_m: 0.6822\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.3567 - acc: 0.9817 - f1_m: 0.7663 - precision_m: 0.9775 - recall_m: 0.6315\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.3431 - acc: 0.9866 - f1_m: 0.8510 - precision_m: 0.9855 - recall_m: 0.7497\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.3326 - acc: 0.9885 - f1_m: 0.9592 - precision_m: 0.9890 - recall_m: 0.9315\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.3196 - acc: 0.9896 - f1_m: 0.9819 - precision_m: 0.9911 - recall_m: 0.9729\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.3006 - acc: 0.9929 - f1_m: 0.9904 - precision_m: 0.9937 - recall_m: 0.9871\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.2687 - acc: 0.9942 - f1_m: 0.9943 - precision_m: 0.9945 - recall_m: 0.9941\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.2344 - acc: 0.9903 - f1_m: 0.9906 - precision_m: 0.9914 - recall_m: 0.9898\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 9s 2s/step - loss: 0.2028 - acc: 0.9937 - f1_m: 0.9934 - precision_m: 0.9937 - recall_m: 0.9931\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.1674 - acc: 0.9929 - f1_m: 0.9931 - precision_m: 0.9929 - recall_m: 0.9933\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.1365 - acc: 0.9919 - f1_m: 0.9920 - precision_m: 0.9920 - recall_m: 0.9920\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.1071 - acc: 0.9904 - f1_m: 0.9904 - precision_m: 0.9904 - recall_m: 0.9904\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0801 - acc: 0.9909 - f1_m: 0.9914 - precision_m: 0.9917 - recall_m: 0.9910\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0601 - acc: 0.9919 - f1_m: 0.9927 - precision_m: 0.9954 - recall_m: 0.9901\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0503 - acc: 0.9899 - f1_m: 0.9884 - precision_m: 0.9947 - recall_m: 0.9821\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0450 - acc: 0.9879 - f1_m: 0.9863 - precision_m: 0.9906 - recall_m: 0.9819\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0398 - acc: 0.9867 - f1_m: 0.9870 - precision_m: 0.9870 - recall_m: 0.9870\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0384 - acc: 0.9866 - f1_m: 0.9865 - precision_m: 0.9876 - recall_m: 0.9853\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0359 - acc: 0.9871 - f1_m: 0.9858 - precision_m: 0.9906 - recall_m: 0.9810\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0403 - acc: 0.9891 - f1_m: 0.9881 - precision_m: 0.9901 - recall_m: 0.9861\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0380 - acc: 0.9862 - f1_m: 0.9863 - precision_m: 0.9863 - recall_m: 0.9863\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0470 - acc: 0.9757 - f1_m: 0.9749 - precision_m: 0.9749 - recall_m: 0.9749\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0449 - acc: 0.9772 - f1_m: 0.9768 - precision_m: 0.9775 - recall_m: 0.9761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('loss : ',loss)\n",
        "print('accuracy : ',accuracy)\n",
        "print('f1 score : ',f1_score)\n",
        "print('precision : ',precision)\n",
        "print('recall : ',recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5sq_13_IFZO",
        "outputId": "f48f1401-a0ea-40b3-e93e-10510dc72e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.05922591686248779\n",
            "accuracy :  0.9706249833106995\n",
            "f1 score :  0.9706249833106995\n",
            "precision :  0.9706249833106995\n",
            "recall :  0.9706249833106995\n"
          ]
        }
      ]
    }
  ]
}